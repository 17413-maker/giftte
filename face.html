<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Gifté⁺ OmniFusion v5.8 — White Intelligence Adaptive Interface</title>

  <script src="https://cdn.tailwindcss.com"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>

  <style>
    body {
      font-family: "Poppins", sans-serif;
      background: linear-gradient(135deg, #fdfdfd, #e4edf5);
      transition: background 1.5s ease;
      overflow-x: hidden;
      color: #333;
    }

    .glass {
      background: rgba(255, 255, 255, 0.35);
      backdrop-filter: blur(20px);
      border-radius: 1rem;
      box-shadow: 0 0 25px rgba(0, 0, 0, 0.05);
      border: 1px solid rgba(255, 255, 255, 0.6);
      transition: all 0.4s ease;
    }

    video, canvas {
      border-radius: 1rem;
      object-fit: cover;
      width: 100%;
      height: auto;
    }

    .btn {
      padding: 0.6rem 1.3rem;
      border-radius: 0.75rem;
      transition: all 0.4s ease;
      font-weight: 500;
    }

    .btn:hover {
      transform: translateY(-2px);
      box-shadow: 0 5px 15px rgba(0, 0, 0, 0.1);
    }

    .mood-happy { background: linear-gradient(135deg, #fff9c4, #ffe082); }
    .mood-sad { background: linear-gradient(135deg, #cfd8dc, #90caf9); }
    .mood-angry { background: linear-gradient(135deg, #ffcdd2, #ef9a9a); }
    .mood-neutral { background: linear-gradient(135deg, #f5f5f5, #e0e0e0); }
    .mood-surprised { background: linear-gradient(135deg, #fff3e0, #ffe0b2); }

    #logConsole {
      height: 180px;
      overflow-y: auto;
      font-size: 0.8rem;
      font-family: monospace;
      background: rgba(255, 255, 255, 0.3);
      border-radius: 0.75rem;
      padding: 0.75rem;
      color: #333;
    }

    .header-title {
      background: linear-gradient(90deg, #cfd8dc, #fce4ec);
      -webkit-background-clip: text;
      -webkit-text-fill-color: transparent;
      font-weight: 700;
      text-shadow: 0 2px 10px rgba(255, 255, 255, 0.6);
    }

    .fade-bg {
      transition: background 1.5s ease-in-out;
    }

    #overlayText {
      position: absolute;
      bottom: 10px;
      left: 10px;
      font-size: 16px;
      font-weight: bold;
      color: #00e5ff;
      text-shadow: 0 0 10px #00e5ff, 0 0 20px #00e5ff;
      letter-spacing: 1px;
      z-index: 10;
      animation: pulse 2s infinite;
    }

    @keyframes pulse {
      0%, 100% { opacity: 0.8; }
      50% { opacity: 1; }
    }

    ::-webkit-scrollbar {
      width: 6px;
    }
    ::-webkit-scrollbar-thumb {
      background: rgba(180,180,180,0.5);
      border-radius: 4px;
    }
  </style>
</head>

<body class="min-h-screen flex flex-col items-center justify-center transition-all duration-1000">
  <header class="text-center mb-8">
    <h1 class="text-4xl header-title">Gifté⁺ OmniFusion v5.8</h1>
    <p class="opacity-70 text-gray-600">White Intelligence Adaptive Interface</p>
  </header>

  <div id="emotionWrapper" class="w-11/12 max-w-7xl grid grid-cols-1 md:grid-cols-2 gap-6 glass p-6 fade-bg">

    <!-- CAMERA PANEL -->
    <div class="flex flex-col items-center">
      <div class="relative w-full aspect-video bg-gray-900 rounded-2xl overflow-hidden">
        <video id="video" autoplay muted playsinline></video>
        <canvas id="overlay" class="absolute top-0 left-0"></canvas>
        <div id="overlayText"></div>
      </div>

      <div class="flex flex-wrap justify-center gap-3 mt-5">
        <button id="stopCamBtn" class="btn bg-rose-200 hover:bg-rose-300">Stop</button>
        <button id="captureBtn" class="btn bg-sky-200 hover:bg-sky-300">Capture</button>
        <button id="uploadBtn" class="btn bg-indigo-200 hover:bg-indigo-300">Upload</button>
        <button id="analyzeBtn" class="btn bg-amber-200 hover:bg-amber-300">Analyze</button>
      </div>

      <input id="fileInput" type="file" accept="image/*" class="hidden" />

      <div class="mt-4 w-3/4">
        <input id="urlInput" type="text" placeholder="Paste image URL to analyze" class="w-full text-center text-sm p-2 rounded-lg bg-white/40 backdrop-blur-md border border-white/50 shadow-sm focus:outline-none focus:ring-2 focus:ring-pink-200">
      </div>
    </div>

    <!-- STATS PANEL -->
    <div class="flex flex-col justify-between">
      <div class="grid grid-cols-2 gap-3">
        <div class="glass text-center p-3"><p>Gender</p><h3 id="gender" class="text-xl font-bold">—</h3></div>
        <div class="glass text-center p-3"><p>Age</p><h3 id="age" class="text-xl font-bold">—</h3></div>
        <div class="glass text-center p-3 col-span-2"><p>Emotion</p><h3 id="emotion" class="text-xl font-bold">—</h3></div>
        <div class="glass text-center p-3 col-span-2"><p>White Score</p><h3 id="whiteScore" class="text-xl font-bold">—</h3></div>
      </div>

      <div class="mt-5">
        <h3 class="text-gray-700 mb-1">System Log</h3>
        <div id="logConsole"></div>
      </div>
    </div>
  </div>

  <script>
    const MODEL_URL = "https://cdn.jsdelivr.net/gh/vladmandic/face-api/model/";
    const video = document.getElementById("video");
    const overlay = document.getElementById("overlay");
    const ctx = overlay.getContext("2d");
    const logConsole = document.getElementById("logConsole");
    const emotionWrapper = document.getElementById("emotionWrapper");
    const overlayText = document.getElementById("overlayText");

    let stream = null, modelsLoaded = false, detecting = false, interval = null;
    let lastCapture = null;

    // === COMMANDER FACE (HARD-CODED) ===
    const COMMANDER = {
      name: "COMMANDER",
      descriptor: new Float32Array([
        -0.16083209216594696,0.05017932504415512,0.0459735281765461,-0.032153140753507614,-0.10642893612384796,-0.024279797449707985,-0.016587749123573303,-0.04459153860807419,0.13998326659202576,-0.1387113630771637,0.223501056432724,-0.056238848716020584,-0.18469607830047607,-0.11640550941228867,0.005373072344809771,0.1628466248512268,-0.047109201550483704,-0.12886977195739746,-0.13172012567520142,-0.1144687682390213,0.01690208911895752,-0.012262754142284393,-0.049030851572752,0.03428465127944946,-0.153143510222435,-0.37606585025787354,-0.04421274736523628,-0.0779731422662735,-0.086550273001194,-0.12482056766748428,-0.06573786586523056,0.03942761570215225,-0.19311876595020294,-0.10329786688089371,-0.02990395948290825,0.09545929729938507,-0.01545440312474966,0.00020492446492426097,0.12953104078769684,0.011241099797189236,-0.14734318852424622,-0.03318653628230095,0.06391007453203201,0.24473276734352112,0.16301532089710236,0.03514790162444115,0.011051108129322529,-0.005247571039944887,0.1143452525138855,-0.31002387404441833,0.02509089931845665,0.07733290642499924,0.09638552367687225,0.025838328525424004,0.12882199883460999,-0.04652315005660057,-0.04739919304847717,0.10262274742126465,-0.15974248945713043,0.04056687653064728,-0.02864958345890045,-0.025212692096829414,-0.11007564514875412,-0.10185778886079788,0.2285195142030716,0.1837681084871292,-0.07742070406675339,-0.049442701041698456,0.1426328867673874,-0.13016308844089508,-0.013879837468266487,0.0117546571418643,-0.07039899379014969,-0.22863149642944336,-0.25684207677841187,0.10420946776866913,0.4301004409790039,0.17615945637226105,-0.19640059769153595,-0.0016248059691861272,-0.04472290724515915,-0.03912454470992088,0.12125562131404877,-0.015991147607564926,-0.03612816333770752,0.030750785022974014,-0.03667951375246048,0.09984487295150757,0.2004861980676651,-0.01684415526688099,-0.0015315029304474592,0.19162426888942719,-0.019811443984508514,0.03945521265268326,0.02930379845201969,0.012698017992079258,-0.07267976552248001,0.0052163791842758656,-0.12764707207679749,0.0024211627896875143,0.10561194270849228,-0.06062479317188263,0.048583898693323135,0.038937002420425415,-0.12366019189357758,0.07551024109125137,-0.020718086510896683,-0.017041103914380074,-0.0041695511899888515,0.05901838093996048,-0.11841798573732376,-0.06615568697452545,0.10755658149719238,-0.17166779935359955,0.13085755705833435,0.14842034876346588,-0.10567540675401688,0.15291355550289154,0.06675660610198975,0.04313988238573074,0.031687021255493164,-0.016043340787291527,-0.09562312066555023,-0.058347828686237335,0.09513852000236511,-0.007848993875086308,0.05679747089743614,-0.0028732847422361374
      ])
    };

    function euclideanDistance(a, b) {
      let sum = 0;
      for (let i = 0; i < a.length; i++) sum += (a[i] - b[i]) ** 2;
      return Math.sqrt(sum);
    }

    function log(msg) {
      const t = new Date().toLocaleTimeString();
      logConsole.innerHTML += `[${t}] ${msg}<br>`;
      logConsole.scrollTop = logConsole.scrollHeight;
    }

    async function loadModels() {
      try {
        log("Loading AI models...");
        await faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL);
        await faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL);
        await faceapi.nets.faceRecognitionNet.loadFromUri(MODEL_URL);
        await faceapi.nets.faceExpressionNet.loadFromUri(MODEL_URL);
        await faceapi.nets.ageGenderNet.loadFromUri(MODEL_URL);
        modelsLoaded = true;
        log("Models loaded. Starting camera...");
        startCamera();
      } catch (e) {
        log("Model load failed: " + e.message);
      }
    }

    async function startCamera() {
      try {
        stream = await navigator.mediaDevices.getUserMedia({ video: { width: 1280, height: 720 } });
        video.srcObject = stream;
        video.onloadedmetadata = () => {
          video.play();
          overlay.width = video.videoWidth;
          overlay.height = video.videoHeight;
          log("Camera ON. Tracking started.");
          startTracking();
        };
      } catch (e) { log("Camera failed: " + e.message); }
    }

    function stopCamera() {
      if (stream) stream.getTracks().forEach(t => t.stop());
      stopTracking();
      log("Camera stopped.");
    }

    function startTracking() {
      if (!modelsLoaded) return;
      if (detecting) return;
      detecting = true;
      interval = setInterval(detectFaces, 400);
    }

    function stopTracking() {
      detecting = false;
      clearInterval(interval);
    }

    async function detectFaces() {
      if (!video || video.paused || video.ended) return;

      const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions())
        .withFaceLandmarks().withFaceDescriptors().withAgeAndGender().withFaceExpressions();

      ctx.clearRect(0, 0, overlay.width, overlay.height);
      overlayText.textContent = "";

      for (const detection of detections) {
        const distance = euclideanDistance(detection.descriptor, COMMANDER.descriptor);
        const isCommander = distance < 0.55;

        const age = Math.round(detection.age);
        const gender = detection.gender;
        const [emotion] = Object.entries(detection.expressions).sort((a, b) => b[1] - a[1])[0];
        const box = detection.detection.box;

        let whiteScore;
        if (isCommander) {
          whiteScore = 99; // YOU = 99
          drawBlueBox(box);
          overlayText.textContent = "MOST BEAUTIFUL PERSON DETECTED";
        } else {
          const faceData = ctx.getImageData(box.x, box.y, box.width, box.height);
          whiteScore = computeWhiteScore(faceData);
          drawNormalBox(box);
          overlayText.textContent = `Age: ${age} | Gender: ${gender} | Emotion: ${emotion} | White Score: ${whiteScore}/100`;
        }

        updateUI(age, gender, emotion, whiteScore);
      }
    }

    function drawBlueBox(box) {
      ctx.strokeStyle = "#00e5ff";
      ctx.lineWidth = 6;
      ctx.shadowBlur = 25;
      ctx.shadowColor = "#00e5ff";
      ctx.strokeRect(box.x - 5, box.y - 5, box.width + 10, box.height + 10);
      ctx.shadowBlur = 0;
    }

    function drawNormalBox(box) {
      ctx.strokeStyle = "#fff";
      ctx.lineWidth = 3;
      ctx.strokeRect(box.x, box.y, box.width, box.height);
    }

    function luminance(data) {
      let sum = 0;
      for (let i = 0; i < data.length; i += 4) sum += (0.299 * data[i] + 0.587 * data[i + 1] + 0.114 * data[i + 2]);
      return sum / (data.length / 4);
    }

    function computeWhiteScore(faceData) {
      const lum = luminance(faceData.data);
      return Math.min(100, Math.max(0, Math.round(lum / 2.55)));
    }

    function updateUI(age, gender, emotion, whiteScore) {
      document.getElementById("age").textContent = age;
      document.getElementById("gender").textContent = gender;
      document.getElementById("emotion").textContent = emotion;
      document.getElementById("whiteScore").textContent = whiteScore + "/100";

      emotionWrapper.classList.remove("mood-happy","mood-sad","mood-angry","mood-neutral","mood-surprised");
      if (emotion.includes("happy")) emotionWrapper.classList.add("mood-happy");
      else if (emotion.includes("sad")) emotionWrapper.classList.add("mood-sad");
      else if (emotion.includes("angry")) emotionWrapper.classList.add("mood-angry");
      else if (emotion.includes("surprised")) emotionWrapper.classList.add("mood-surprised");
      else emotionWrapper.classList.add("mood-neutral");
    }

    // === IMAGE UPLOAD & URL ===
    document.getElementById("uploadBtn").onclick = () => document.getElementById("fileInput").click();
    document.getElementById("fileInput").onchange = e => {
      const file = e.target.files[0];
      if (file) processImage(URL.createObjectURL(file));
    };

    async function processImage(url) {
      const img = new Image();
      img.crossOrigin = "anonymous";
      img.onload = async () => {
        overlay.width = img.width;
        overlay.height = img.height;
        const detections = await faceapi.detectAllFaces(img, new faceapi.TinyFaceDetectorOptions())
          .withFaceLandmarks().withFaceDescriptors().withAgeAndGender().withFaceExpressions();

        ctx.clearRect(0, 0, overlay.width, overlay.height);
        overlayText.textContent = "";

        for (const d of detections) {
          const dist = euclideanDistance(d.descriptor, COMMANDER.descriptor);
          const isCommander = dist < 0.55;
          const age = Math.round(d.age);
          const gender = d.gender;
          const [emotion] = Object.entries(d.expressions).sort((a, b) => b[1] - a[1])[0];
          const box = d.detection.box;

          let whiteScore;
          if (isCommander) {
            whiteScore = 99;
            drawBlueBox(box);
            overlayText.textContent = "MOST BEAUTIFUL PERSON DETECTED";
          } else {
            const faceData = ctx.getImageData(box.x, box.y, box.width, box.height);
            whiteScore = computeWhiteScore(faceData);
            drawNormalBox(box);
            overlayText.textContent = `Age: ${age} | Gender: ${gender} | Emotion: ${emotion} | White Score: ${whiteScore}/100`;
          }
          updateUI(age, gender, emotion, whiteScore);
        }
        log(`Processed ${detections.length} face(s).`);
      };
      img.src = url;
    }

    document.getElementById("captureBtn").onclick = () => {
      const snap = document.createElement("canvas");
      snap.width = video.videoWidth;
      snap.height = video.videoHeight;
      snap.getContext("2d").drawImage(video, 0, 0);
      lastCapture = snap;
      log("Snapshot captured.");
    };

    document.getElementById("analyzeBtn").onclick = async () => {
      const url = document.getElementById("urlInput").value.trim();
      if (url) return processImage(url);
      if (!lastCapture) return log("No snapshot to analyze.");
      await processImage(lastCapture.toDataURL());
    };

    document.getElementById("stopCamBtn").onclick = stopCamera;

    // === AUTO-START ON LOAD ===
    window.onload = () => {
      log("Gifté⁺ OmniFusion v5.8 — AUTO MODE ACTIVE");
      loadModels();
    };
  </script>
</body>
</html>